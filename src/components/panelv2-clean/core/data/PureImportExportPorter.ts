/**
 * @file çº¯å‡€å¯¼å…¥å¯¼å‡ºé—¨æˆ· - å¢å¼ºç‰ˆ
 * @description ç¬¬ä¸€å±‚å¯¼å…¥å¯¼å‡ºæ¥å£ - æ”¯æŒå¤šç§æ•°æ®æ ¼å¼çš„é€šç”¨è½¬æ¢æ¡†æ¶
 * 
 * åŠŸèƒ½ç‰¹æ€§ï¼š
 * - ğŸ“„ å¤šæ ¼å¼æ”¯æŒï¼šJSONã€XMLã€CSVã€YAMLã€Binaryç­‰
 * - ğŸ”„ æ•°æ®è½¬æ¢ï¼šè‡ªåŠ¨æ ¼å¼æ£€æµ‹å’Œæ™ºèƒ½è½¬æ¢
 * - âœ… æ•°æ®éªŒè¯ï¼šSchemaéªŒè¯å’Œå®Œæ•´æ€§æ£€æŸ¥
 * - ğŸ“Š è¿›åº¦è·Ÿè¸ªï¼šå¤§æ–‡ä»¶å¤„ç†çš„è¿›åº¦åé¦ˆ
 * - ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šæµå¼å¤„ç†å’Œå†…å­˜ç®¡ç†
 * - ğŸ”§ å¯æ‰©å±•ï¼šæ’ä»¶åŒ–æ ¼å¼å¤„ç†å™¨
 */

import { reactive, ref } from 'vue'
import { nanoid } from 'nanoid'
import type {
  ImportExportPorter as IImportExportPorter,
  DataImporter,
  DataExporter,
  ImportResult,
  ImportOptions,
  ExportOptions,
  ValidationResult
} from './interfaces/PureInfrastructure'

/**
 * æ•°æ®æ ¼å¼ç±»å‹æšä¸¾
 */
export enum DataFormat {
  JSON = 'json',
  XML = 'xml', 
  CSV = 'csv',
  YAML = 'yaml',
  BINARY = 'binary',
  TEXT = 'text',
  EXCEL = 'excel',
  PDF = 'pdf'
}

/**
 * æ•°æ®è½¬æ¢ç»“æœ
 */
interface TransformResult {
  success: boolean
  data?: any
  errors?: string[]
  warnings?: string[]
  metadata?: {
    originalFormat: string
    targetFormat: string
    transformTime: number
    dataSize: number
  }
}

/**
 * è¿›åº¦å›è°ƒå‡½æ•°ç±»å‹
 */
export type ProgressCallback = (progress: {
  current: number
  total: number
  percentage: number
  stage: string
  message?: string
}) => void

/**
 * å¢å¼ºçš„å¯¼å…¥é€‰é¡¹
 */
export interface EnhancedImportOptions extends ImportOptions {
  // æ•°æ®è½¬æ¢é€‰é¡¹
  autoDetectFormat?: boolean
  targetFormat?: DataFormat
  encoding?: string
  
  // éªŒè¯é€‰é¡¹
  schema?: any
  strictValidation?: boolean
  
  // æ€§èƒ½é€‰é¡¹
  chunkSize?: number
  useStreaming?: boolean
  onProgress?: ProgressCallback
  
  // æ•°æ®å¤„ç†é€‰é¡¹
  transformData?: (data: any) => any
  filterData?: (item: any) => boolean
  
  // é”™è¯¯å¤„ç†
  continueOnError?: boolean
  maxErrors?: number
}

/**
 * å¢å¼ºçš„å¯¼å‡ºé€‰é¡¹
 */
export interface EnhancedExportOptions extends ExportOptions {
  // æ ¼å¼é€‰é¡¹
  format: DataFormat
  encoding?: string
  compression?: boolean
  
  // å†…å®¹é€‰é¡¹
  includeSchema?: boolean
  includeTimestamp?: boolean
  customMetadata?: Record<string, any>
  
  // æ€§èƒ½é€‰é¡¹
  chunkSize?: number
  onProgress?: ProgressCallback
  
  // è¿‡æ»¤é€‰é¡¹
  fields?: string[]
  excludeFields?: string[]
  dataFilter?: (item: any) => boolean
}

/**
 * é—¨æˆ·ç»Ÿè®¡ä¿¡æ¯ - å¢å¼ºç‰ˆ
 */
interface EnhancedPorterStats {
  // åŸºç¡€ç»Ÿè®¡
  totalImports: number
  totalExports: number
  successfulImports: number
  successfulExports: number
  errors: number
  warnings: number
  lastOperation: number
  
  // æ ¼å¼ç»Ÿè®¡
  formatStats: Record<string, {
    imports: number
    exports: number
    errors: number
    avgProcessingTime: number
  }>
  
  // æ€§èƒ½ç»Ÿè®¡
  performanceStats: {
    avgImportTime: number
    avgExportTime: number
    totalDataProcessed: number
    largestFileSize: number
  }
  
  // é”™è¯¯ç»Ÿè®¡
  errorCategories: Record<string, number>
}

/**
 * æ•°æ®æºæ¥å£ - ç”¨äºä¾èµ–æ³¨å…¥
 */
export interface DataSource {
  getPanelData(): Promise<any>
  setPanelData(data: any): Promise<void>
}

/**
 * å¢å¼ºçš„æ•°æ®æ ¼å¼å¤„ç†å™¨æ¥å£
 */
export interface EnhancedDataProcessor {
  // åŸºç¡€å¤„ç†æ–¹æ³•
  import(data: string | ArrayBuffer, options?: EnhancedImportOptions): Promise<any>
  export(data: any, options?: EnhancedExportOptions): Promise<string | ArrayBuffer>
  validate(data: string | ArrayBuffer): ValidationResult
  
  // æ ¼å¼æ£€æµ‹
  detectFormat?(data: string | ArrayBuffer): string | null
  
  // æ•°æ®è½¬æ¢
  transform?(data: any, targetFormat: DataFormat): Promise<TransformResult>
  
  // æµå¼å¤„ç†æ”¯æŒ
  supportsStreaming?: boolean
  processChunk?(chunk: any, options?: any): Promise<any>
  
  // æ”¯æŒçš„é€‰é¡¹
  getSupportedOptions(): Record<string, string>
  
  // æ ¼å¼ç‰¹å®šæ–¹æ³•
  getSchema?(): any
  validateSchema?(data: any, schema: any): ValidationResult
}

/**
 * çº¯å‡€å¯¼å…¥å¯¼å‡ºé—¨æˆ·å®ç° - å¢å¼ºç‰ˆ
 * 
 * è¿™å°±åƒä¸€ä¸ªç°ä»£åŒ–çš„æ•°æ®å¤„ç†ä¸­å¿ƒï¼š
 * - æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼ï¼Œå°±åƒä¸‡èƒ½è½¬æ¢å™¨
 * - è‡ªåŠ¨è¯†åˆ«æ•°æ®æ ¼å¼ï¼Œå°±åƒæ™ºèƒ½åŠ©æ‰‹
 * - æä¾›è¯¦ç»†çš„å¤„ç†è¿›åº¦ï¼Œå°±åƒå®æ—¶ç›‘æ§ç³»ç»Ÿ
 * - ç¡®ä¿æ•°æ®å®‰å…¨å’Œå®Œæ•´æ€§ï¼Œå°±åƒé“¶è¡Œçº§å®‰å…¨
 */
export class PureImportExportPorter implements IImportExportPorter {
  /** å¢å¼ºçš„å¤„ç†å™¨æ³¨å†Œè¡¨ */
  private processors = new Map<string, EnhancedDataProcessor>()
  
  /** æ•°æ®æº - ç”¨äºä¾èµ–æ³¨å…¥ */
  private dataSource: DataSource | null = null
  
  /** å¢å¼ºçš„é—¨æˆ·ç»Ÿè®¡ */
  private stats = reactive<EnhancedPorterStats>({
    // åŸºç¡€ç»Ÿè®¡
    totalImports: 0,
    totalExports: 0,
    successfulImports: 0,
    successfulExports: 0,
    errors: 0,
    warnings: 0,
    lastOperation: Date.now(),
    
    // æ ¼å¼ç»Ÿè®¡
    formatStats: {},
    
    // æ€§èƒ½ç»Ÿè®¡
    performanceStats: {
      avgImportTime: 0,
      avgExportTime: 0,
      totalDataProcessed: 0,
      largestFileSize: 0
    },
    
    // é”™è¯¯ç»Ÿè®¡
    errorCategories: {}
  })
  
  /** å½“å‰å¤„ç†ä»»åŠ¡é˜Ÿåˆ— */
  private activeJobs = new Map<string, {
    id: string
    type: 'import' | 'export'
    format: string
    startTime: number
    progress: number
    onProgress?: ProgressCallback
  }>()
  
  /** æ ¼å¼æ£€æµ‹ç¼“å­˜ */
  private formatDetectionCache = new Map<string, string>()

  constructor() {
    console.log('PureImportExportPorter Enhanced: å¢å¼ºç‰ˆå¯¼å…¥å¯¼å‡ºé—¨æˆ·å·²åˆå§‹åŒ–')
    this.registerBuiltInProcessors()
  }

  /**
   * æ³¨å†Œå¢å¼ºçš„æ•°æ®å¤„ç†å™¨
   * 
   * è¿™å°±åƒæ³¨å†Œä¸€ä¸ªæ–°çš„"ç¿»è¯‘å®˜"ï¼š
   * - æ¯ç§æ ¼å¼éƒ½æœ‰ä¸“é—¨çš„å¤„ç†ä¸“å®¶
   * - æ”¯æŒå¯¼å…¥ã€å¯¼å‡ºã€éªŒè¯ç­‰å…¨å¥—æœåŠ¡
   * - å¯ä»¥å¤„ç†å¤æ‚çš„æ•°æ®è½¬æ¢éœ€æ±‚
   */
  registerProcessor(format: string, processor: EnhancedDataProcessor): void {
    try {
      console.log('PureImportExportPorter: æ³¨å†Œæ•°æ®å¤„ç†å™¨', format)
      
      if (this.processors.has(format)) {
        console.warn(`PureImportExportPorter: æ•°æ®å¤„ç†å™¨ ${format} å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–`)
      }
      
      this.processors.set(format, processor)
      
      // åˆå§‹åŒ–æ ¼å¼ç»Ÿè®¡
      if (!this.stats.formatStats[format]) {
        this.stats.formatStats[format] = {
          imports: 0,
          exports: 0,
          errors: 0,
          avgProcessingTime: 0
        }
      }
      
      console.log(`PureImportExportPorter: æ•°æ®å¤„ç†å™¨ ${format} æ³¨å†ŒæˆåŠŸ`)
      
    } catch (error) {
      console.error(`PureImportExportPorter: æ³¨å†Œæ•°æ®å¤„ç†å™¨ ${format} å¤±è´¥`, error)
      this.stats.errors++
      this.updateErrorCategory('registration_error')
    }
  }

  /**
   * å…¼å®¹æ€§æ–¹æ³•ï¼šæ³¨å†Œå¯¼å…¥å™¨
   * 
   * ä¸ºäº†å‘åå…¼å®¹ï¼Œå°†ä¼ ç»Ÿçš„å¯¼å…¥å™¨åŒ…è£…ä¸ºå¢å¼ºå¤„ç†å™¨
   */
  registerImporter(format: string, importer: DataImporter): void {
    const enhancedProcessor: EnhancedDataProcessor = {
      import: async (data: string | ArrayBuffer, options?: EnhancedImportOptions) => {
        const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
        return await importer.import(stringData, options)
      },
      export: async () => {
        throw new Error(`æ ¼å¼ ${format} åªæ”¯æŒå¯¼å…¥æ“ä½œ`)
      },
      validate: (data: string | ArrayBuffer): ValidationResult => {
        const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
        return importer.validate(stringData)
      },
      getSupportedOptions: () => importer.getSupportedOptions?.() || {}
    }
    
    this.registerProcessor(format, enhancedProcessor)
  }

  /**
   * å…¼å®¹æ€§æ–¹æ³•ï¼šæ³¨å†Œå¯¼å‡ºå™¨
   * 
   * ä¸ºäº†å‘åå…¼å®¹ï¼Œå°†ä¼ ç»Ÿçš„å¯¼å‡ºå™¨åŒ…è£…ä¸ºå¢å¼ºå¤„ç†å™¨
   */
  registerExporter(format: string, exporter: DataExporter): void {
    const enhancedProcessor: EnhancedDataProcessor = {
      import: async () => {
        throw new Error(`æ ¼å¼ ${format} åªæ”¯æŒå¯¼å‡ºæ“ä½œ`)
      },
      export: async (data: any, options?: EnhancedExportOptions) => {
        return await exporter.export(data, options)
      },
      validate: (): ValidationResult => ({
        isValid: true,
        errors: [],
        warnings: []
      }),
      getSupportedOptions: () => exporter.getSupportedOptions?.() || {}
    }
    
    this.registerProcessor(format, enhancedProcessor)
  }

  /**
   * å¢å¼ºçš„æ•°æ®å¯¼å…¥æ–¹æ³•
   * 
   * è¿™å°±åƒä¸€ä¸ªæ™ºèƒ½çš„æ•°æ®æ¥æ”¶ç«™ï¼š
   * - è‡ªåŠ¨è¯†åˆ«æ•°æ®æ ¼å¼ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
   * - æä¾›å®æ—¶è¿›åº¦åé¦ˆ
   * - æ”¯æŒå¤§æ–‡ä»¶çš„åˆ†å—å¤„ç†
   * - è¿›è¡Œå…¨é¢çš„æ•°æ®éªŒè¯
   * - è‡ªåŠ¨æ•°æ®è½¬æ¢å’Œæ¸…ç†
   */
  async import(format: string, data: string | ArrayBuffer, options: EnhancedImportOptions = {}): Promise<ImportResult> {
    const jobId = nanoid()
    const startTime = Date.now()
    
    try {
      console.log('PureImportExportPorter Enhanced: å¼€å§‹å¢å¼ºå¯¼å…¥', { format, jobId, options })
      
      // æ›´æ–°ç»Ÿè®¡
      this.stats.totalImports++
      this.stats.lastOperation = startTime
      
      // æ³¨å†Œä»»åŠ¡
      this.activeJobs.set(jobId, {
        id: jobId,
        type: 'import',
        format,
        startTime,
        progress: 0,
        onProgress: options.onProgress
      })
      
      // Step 1: æ ¼å¼æ£€æµ‹å’ŒéªŒè¯
      this.updateProgress(jobId, 10, 'format_detection', 'æ£€æµ‹æ•°æ®æ ¼å¼...')
      
      let actualFormat = format
      if (options.autoDetectFormat && format === 'auto') {
        actualFormat = await this.detectDataFormat(data)
        console.log('PureImportExportPorter: è‡ªåŠ¨æ£€æµ‹åˆ°æ ¼å¼', actualFormat)
      }
      
      const processor = this.processors.get(actualFormat)
      if (!processor) {
        throw new Error(`ä¸æ”¯æŒçš„å¯¼å…¥æ ¼å¼: ${actualFormat}`)
      }
      
      // Step 2: æ•°æ®é¢„å¤„ç†
      this.updateProgress(jobId, 20, 'preprocessing', 'é¢„å¤„ç†æ•°æ®...')
      
      let processedData = data
      const dataSize = this.calculateDataSize(data)
      
      // æ›´æ–°æ–‡ä»¶å¤§å°ç»Ÿè®¡
      if (dataSize > this.stats.performanceStats.largestFileSize) {
        this.stats.performanceStats.largestFileSize = dataSize
      }
      
      // Step 3: æ•°æ®éªŒè¯
      if (options.validate !== false) {
        this.updateProgress(jobId, 30, 'validation', 'éªŒè¯æ•°æ®æ ¼å¼...')
        
        const validation = processor.validate(processedData)
        if (!validation.isValid) {
          if (options.strictValidation) {
            return {
              success: false,
              errors: validation.errors,
              warnings: validation.warnings
            }
          } else {
            console.warn('PureImportExportPorter: æ•°æ®éªŒè¯è­¦å‘Š', validation.warnings)
            this.stats.warnings += validation.warnings?.length || 0
          }
        }
        
        // Schema éªŒè¯
        if (options.schema) {
          const schemaValidation = processor.validateSchema?.(processedData, options.schema)
          if (schemaValidation && !schemaValidation.isValid) {
            return {
              success: false,
              errors: schemaValidation.errors,
              warnings: schemaValidation.warnings
            }
          }
        }
      }
      
      // Step 4: æ•°æ®å¯¼å…¥
      this.updateProgress(jobId, 50, 'importing', 'å¯¼å…¥æ•°æ®...')
      
      let importedData: any
      
      if (options.useStreaming && processor.supportsStreaming && dataSize > (options.chunkSize || 1024 * 1024)) {
        // æµå¼å¤„ç†å¤§æ–‡ä»¶
        importedData = await this.processDataInChunks(processor, processedData, options, jobId)
      } else {
        // æ™®é€šå¤„ç†
        importedData = await processor.import(processedData, options)
      }
      
      // Step 5: æ•°æ®è½¬æ¢å’Œè¿‡æ»¤
      this.updateProgress(jobId, 70, 'transforming', 'è½¬æ¢æ•°æ®æ ¼å¼...')
      
      if (options.transformData) {
        importedData = options.transformData(importedData)
      }
      
      if (options.filterData && Array.isArray(importedData)) {
        importedData = importedData.filter(options.filterData)
      }
      
      // Step 6: æ ¼å¼è½¬æ¢
      if (options.targetFormat && options.targetFormat !== actualFormat) {
        this.updateProgress(jobId, 80, 'format_conversion', 'è½¬æ¢ç›®æ ‡æ ¼å¼...')
        
        if (processor.transform) {
          const transformResult = await processor.transform(importedData, options.targetFormat)
          if (transformResult.success) {
            importedData = transformResult.data
          } else {
            console.warn('PureImportExportPorter: æ ¼å¼è½¬æ¢å¤±è´¥', transformResult.errors)
          }
        }
      }
      
      // Step 7: æ•°æ®æŒä¹…åŒ–
      if (this.dataSource && options.overwrite) {
        this.updateProgress(jobId, 90, 'persisting', 'ä¿å­˜æ•°æ®...')
        await this.dataSource.setPanelData(importedData)
      }
      
      // å®Œæˆå¤„ç†
      this.updateProgress(jobId, 100, 'completed', 'å¯¼å…¥å®Œæˆ')
      
      // æ›´æ–°ç»Ÿè®¡
      const processingTime = Date.now() - startTime
      this.updateStats(actualFormat, 'import', processingTime, dataSize, true)
      
      this.stats.successfulImports++
      this.stats.performanceStats.totalDataProcessed += dataSize
      
      const result: ImportResult = {
        success: true,
        data: importedData,
        metadata: {
          format: actualFormat,
          dataSize,
          processingTime,
          jobId
        }
      }
      
      console.log('PureImportExportPorter Enhanced: å¯¼å…¥æˆåŠŸ', { format: actualFormat, jobId, processingTime })
      return result
      
    } catch (error) {
      console.error('PureImportExportPorter Enhanced: å¯¼å…¥å¤±è´¥', error)
      
      // æ›´æ–°é”™è¯¯ç»Ÿè®¡
      this.stats.errors++
      this.updateErrorCategory('import_error')
      this.updateStats(format, 'import', Date.now() - startTime, 0, false)
      
      return {
        success: false,
        errors: [error instanceof Error ? error.message : 'å¯¼å…¥å¤±è´¥'],
        metadata: {
          format,
          jobId,
          processingTime: Date.now() - startTime
        }
      }
    } finally {
      // æ¸…ç†ä»»åŠ¡
      this.activeJobs.delete(jobId)
    }
  }

  /**
   * å¢å¼ºçš„æ•°æ®å¯¼å‡ºæ–¹æ³•
   * 
   * è¿™å°±åƒä¸€ä¸ªæ™ºèƒ½çš„æ•°æ®å‘é€ç«™ï¼š
   * - æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ï¼ˆJSONã€XMLã€CSVç­‰ï¼‰
   * - æä¾›å®æ—¶è¿›åº¦åé¦ˆ
   * - æ”¯æŒæ•°æ®è¿‡æ»¤å’Œå­—æ®µé€‰æ‹©
   * - è‡ªåŠ¨å‹ç¼©å’Œä¼˜åŒ–è¾“å‡º
   * - åŒ…å«å®Œæ•´çš„å…ƒæ•°æ®ä¿¡æ¯
   */
  async export(format: string, options: EnhancedExportOptions): Promise<string | ArrayBuffer> {
    const jobId = nanoid()
    const startTime = Date.now()
    
    try {
      console.log('PureImportExportPorter Enhanced: å¼€å§‹å¢å¼ºå¯¼å‡º', { format, jobId, options })
      
      // æ›´æ–°ç»Ÿè®¡
      this.stats.totalExports++
      this.stats.lastOperation = startTime
      
      // æ³¨å†Œä»»åŠ¡
      this.activeJobs.set(jobId, {
        id: jobId,
        type: 'export',
        format,
        startTime,
        progress: 0,
        onProgress: options.onProgress
      })
      
      const processor = this.processors.get(format)
      if (!processor) {
        throw new Error(`ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: ${format}`)
      }
      
      // Step 1: å‡†å¤‡å¯¼å‡ºæ•°æ®
      this.updateProgress(jobId, 10, 'data_preparation', 'å‡†å¤‡å¯¼å‡ºæ•°æ®...')
      
      let exportData = await this.prepareExportData(options)
      const originalDataSize = this.calculateDataSize(JSON.stringify(exportData))
      
      // Step 2: æ•°æ®è¿‡æ»¤
      if (options.fields || options.excludeFields || options.dataFilter) {
        this.updateProgress(jobId, 20, 'data_filtering', 'è¿‡æ»¤å¯¼å‡ºæ•°æ®...')
        exportData = this.filterExportData(exportData, options)
      }
      
      // Step 3: æ•°æ®è½¬æ¢
      this.updateProgress(jobId, 40, 'data_transformation', 'è½¬æ¢æ•°æ®æ ¼å¼...')
      
      // æ·»åŠ å…ƒæ•°æ®
      if (options.includeTimestamp || options.includeSchema || options.customMetadata) {
        exportData = this.addExportMetadata(exportData, options)
      }
      
      // Step 4: æ ¼å¼è½¬æ¢å’Œåºåˆ—åŒ–
      this.updateProgress(jobId, 60, 'serialization', 'åºåˆ—åŒ–æ•°æ®...')
      
      let result = await processor.export(exportData, options)
      
      // Step 5: åå¤„ç†ï¼ˆå‹ç¼©ç­‰ï¼‰
      if (options.compression && typeof result === 'string') {
        this.updateProgress(jobId, 80, 'compression', 'å‹ç¼©æ•°æ®...')
        result = await this.compressData(result, options)
      }
      
      // Step 6: ç¼–ç å¤„ç†
      if (options.encoding && options.encoding !== 'utf-8' && typeof result === 'string') {
        this.updateProgress(jobId, 90, 'encoding', 'è½¬æ¢ç¼–ç ...')
        result = this.convertEncoding(result, options.encoding)
      }
      
      // å®Œæˆå¤„ç†
      this.updateProgress(jobId, 100, 'completed', 'å¯¼å‡ºå®Œæˆ')
      
      // æ›´æ–°ç»Ÿè®¡
      const processingTime = Date.now() - startTime
      const finalDataSize = this.calculateDataSize(result)
      this.updateStats(format, 'export', processingTime, finalDataSize, true)
      
      this.stats.successfulExports++
      this.stats.performanceStats.totalDataProcessed += originalDataSize
      
      console.log('PureImportExportPorter Enhanced: å¯¼å‡ºæˆåŠŸ', { 
        format, 
        jobId, 
        processingTime,
        originalSize: originalDataSize,
        finalSize: finalDataSize,
        compressionRatio: originalDataSize > 0 ? (1 - finalDataSize / originalDataSize) * 100 : 0
      })
      
      return result
      
    } catch (error) {
      console.error('PureImportExportPorter Enhanced: å¯¼å‡ºå¤±è´¥', error)
      
      // æ›´æ–°é”™è¯¯ç»Ÿè®¡
      this.stats.errors++
      this.updateErrorCategory('export_error')
      this.updateStats(format, 'export', Date.now() - startTime, 0, false)
      
      throw error
    } finally {
      // æ¸…ç†ä»»åŠ¡
      this.activeJobs.delete(jobId)
    }
  }

  /**
   * è·å–æ”¯æŒçš„æ ¼å¼ - å¢å¼ºç‰ˆ
   * 
   * è¿”å›è¯¦ç»†çš„æ ¼å¼æ”¯æŒä¿¡æ¯ï¼ŒåŒ…æ‹¬æ¯ç§æ ¼å¼çš„èƒ½åŠ›
   */
  getSupportedFormats(): { 
    formats: string[]
    capabilities: Record<string, {
      import: boolean
      export: boolean
      streaming: boolean
      validation: boolean
      transformation: boolean
      options: Record<string, string>
    }>
  } {
    const formats = Array.from(this.processors.keys())
    const capabilities: Record<string, any> = {}
    
    for (const [format, processor] of this.processors.entries()) {
      capabilities[format] = {
        import: true, // æ‰€æœ‰å¤„ç†å™¨éƒ½æ”¯æŒå¯¼å…¥ï¼ˆå³ä½¿åªæ˜¯æŠ›å‡ºé”™è¯¯ï¼‰
        export: true, // æ‰€æœ‰å¤„ç†å™¨éƒ½æ”¯æŒå¯¼å‡º
        streaming: processor.supportsStreaming || false,
        validation: true, // æ‰€æœ‰å¤„ç†å™¨éƒ½æœ‰validateæ–¹æ³•
        transformation: !!processor.transform,
        options: processor.getSupportedOptions()
      }
    }
    
    return { formats, capabilities }
  }

  /**
   * è·å–å¢å¼ºçš„é—¨æˆ·ç»Ÿè®¡
   */
  getStats(): EnhancedPorterStats {
    return { ...this.stats }
  }

  /**
   * è·å–å½“å‰æ´»è·ƒä»»åŠ¡
   */
  getActiveJobs(): Array<{
    id: string
    type: 'import' | 'export'
    format: string
    startTime: number
    progress: number
    duration: number
  }> {
    const now = Date.now()
    return Array.from(this.activeJobs.values()).map(job => ({
      ...job,
      duration: now - job.startTime
    }))
  }

  /**
   * å–æ¶ˆæ´»è·ƒä»»åŠ¡
   */
  cancelJob(jobId: string): boolean {
    const job = this.activeJobs.get(jobId)
    if (job) {
      this.activeJobs.delete(jobId)
      console.log('PureImportExportPorter: ä»»åŠ¡å·²å–æ¶ˆ', jobId)
      return true
    }
    return false
  }

  /**
   * è®¾ç½®æ•°æ®æº - ç”¨äºä¾èµ–æ³¨å…¥
   */
  setDataSource(dataSource: DataSource): void {
    console.log('PureImportExportPorter: è®¾ç½®æ•°æ®æº')
    this.dataSource = dataSource
  }

  // ==================== ç§æœ‰æ–¹æ³• ====================

  /**
   * æ³¨å†Œå†…ç½®æ•°æ®å¤„ç†å™¨
   * 
   * å†…ç½®æ”¯æŒçš„æ ¼å¼ï¼š
   * - JSON: æœ€å¸¸ç”¨çš„æ•°æ®äº¤æ¢æ ¼å¼
   * - XML: ä¼ä¸šçº§æ•°æ®æ ¼å¼
   * - CSV: è¡¨æ ¼æ•°æ®æ ¼å¼
   * - YAML: é…ç½®æ–‡ä»¶æ ¼å¼
   * - TEXT: çº¯æ–‡æœ¬æ ¼å¼
   */
  private registerBuiltInProcessors(): void {
    console.log('PureImportExportPorter: å¼€å§‹æ³¨å†Œå†…ç½®å¤„ç†å™¨')

    // JSON å¤„ç†å™¨ - å¢å¼ºç‰ˆ
    this.registerProcessor(DataFormat.JSON, {
      import: async (data: string | ArrayBuffer, options?: EnhancedImportOptions) => {
        const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
        const importData = JSON.parse(stringData)
        
        // è¯†åˆ«å¯¼å…¥æ•°æ®çš„æ ¼å¼
        let panelData = null
        
        if (importData.panel) {
          panelData = importData.panel
        } else if (importData.meta || importData.nodes) {
          panelData = importData
        } else {
          throw new Error('æ— æ³•è¯†åˆ«çš„JSONæ•°æ®æ ¼å¼')
        }
        
        return { panel: panelData, metadata: importData.metadata }
      },
      
      export: async (data: any, options?: EnhancedExportOptions) => {
        const indent = options?.compression ? 0 : 2
        return JSON.stringify(data, null, indent)
      },
      
      validate: (data: string | ArrayBuffer): ValidationResult => {
        try {
          const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
          JSON.parse(stringData)
          return { isValid: true, errors: [], warnings: [] }
        } catch (error) {
          return {
            isValid: false,
            errors: ['æ— æ•ˆçš„JSONæ ¼å¼: ' + (error as Error).message],
            warnings: []
          }
        }
      },
      
      detectFormat: (data: string | ArrayBuffer): string | null => {
        try {
          const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
          JSON.parse(stringData)
          return DataFormat.JSON
        } catch {
          return null
        }
      },
      
      getSupportedOptions: () => ({
        compression: 'boolean',
        includeMetadata: 'boolean',
        overwrite: 'boolean',
        validate: 'boolean'
      })
    })

    // XML å¤„ç†å™¨
    this.registerProcessor(DataFormat.XML, {
      import: async (data: string | ArrayBuffer, options?: EnhancedImportOptions) => {
        const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
        
        // ç®€åŒ–çš„XMLè§£æï¼ˆå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨ä¸“ä¸šçš„XMLè§£æåº“ï¼‰
        try {
          const parser = new DOMParser()
          const xmlDoc = parser.parseFromString(stringData, 'text/xml')
          
          // æ£€æŸ¥è§£æé”™è¯¯
          const parseError = xmlDoc.querySelector('parsererror')
          if (parseError) {
            throw new Error('XMLè§£æå¤±è´¥: ' + parseError.textContent)
          }
          
          // è½¬æ¢XMLä¸ºJSONæ ¼å¼
          const jsonData = this.xmlToJson(xmlDoc.documentElement)
          return jsonData
          
        } catch (error) {
          throw new Error('XMLå¯¼å…¥å¤±è´¥: ' + (error as Error).message)
        }
      },
      
      export: async (data: any, options?: EnhancedExportOptions) => {
        // ç®€åŒ–çš„JSONåˆ°XMLè½¬æ¢
        return this.jsonToXml(data, options?.compression ? '' : '  ')
      },
      
      validate: (data: string | ArrayBuffer): ValidationResult => {
        try {
          const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
          const parser = new DOMParser()
          const xmlDoc = parser.parseFromString(stringData, 'text/xml')
          
          const parseError = xmlDoc.querySelector('parsererror')
          if (parseError) {
            return {
              isValid: false,
              errors: ['XMLæ ¼å¼é”™è¯¯: ' + parseError.textContent],
              warnings: []
            }
          }
          
          return { isValid: true, errors: [], warnings: [] }
        } catch (error) {
          return {
            isValid: false,
            errors: ['XMLéªŒè¯å¤±è´¥: ' + (error as Error).message],
            warnings: []
          }
        }
      },
      
      detectFormat: (data: string | ArrayBuffer): string | null => {
        const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
        return stringData.trim().startsWith('<?xml') || stringData.trim().startsWith('<') ? DataFormat.XML : null
      },
      
      getSupportedOptions: () => ({
        compression: 'boolean',
        rootElement: 'string',
        encoding: 'string'
      })
    })

    // CSV å¤„ç†å™¨
    this.registerProcessor(DataFormat.CSV, {
      import: async (data: string | ArrayBuffer, options?: EnhancedImportOptions) => {
        const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
        const lines = stringData.split('\n').filter(line => line.trim())
        
        if (lines.length === 0) {
          throw new Error('CSVæ–‡ä»¶ä¸ºç©º')
        }
        
        // è§£æCSVæ•°æ®
        const headers = this.parseCSVLine(lines[0])
        const rows = lines.slice(1).map(line => {
          const values = this.parseCSVLine(line)
          const obj: any = {}
          headers.forEach((header, index) => {
            obj[header] = values[index] || ''
          })
          return obj
        })
        
        return {
          headers,
          data: rows,
          rowCount: rows.length
        }
      },
      
      export: async (data: any, options?: EnhancedExportOptions) => {
        // å°†JSONæ•°æ®è½¬æ¢ä¸ºCSV
        if (!Array.isArray(data)) {
          throw new Error('CSVå¯¼å‡ºéœ€è¦æ•°ç»„æ•°æ®')
        }
        
        if (data.length === 0) {
          return ''
        }
        
        // è·å–æ‰€æœ‰å­—æ®µ
        const allFields = new Set<string>()
        data.forEach(item => {
          if (typeof item === 'object' && item !== null) {
            Object.keys(item).forEach(key => allFields.add(key))
          }
        })
        
        const fields = options?.fields || Array.from(allFields)
        
        // ç”ŸæˆCSVå†…å®¹
        const csvLines = []
        csvLines.push(fields.map(field => this.escapeCSVField(field)).join(','))
        
        data.forEach(item => {
          const values = fields.map(field => {
            const value = item[field]
            return this.escapeCSVField(value != null ? String(value) : '')
          })
          csvLines.push(values.join(','))
        })
        
        return csvLines.join('\n')
      },
      
      validate: (data: string | ArrayBuffer): ValidationResult => {
        try {
          const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
          const lines = stringData.split('\n').filter(line => line.trim())
          
          if (lines.length < 2) {
            return {
              isValid: false,
              errors: ['CSVè‡³å°‘éœ€è¦åŒ…å«æ ‡é¢˜è¡Œå’Œæ•°æ®è¡Œ'],
              warnings: []
            }
          }
          
          // ç®€å•éªŒè¯ï¼šæ£€æŸ¥æ¯è¡Œçš„å­—æ®µæ•°æ˜¯å¦ä¸€è‡´
          const headerFieldCount = this.parseCSVLine(lines[0]).length
          const warnings: string[] = []
          
          for (let i = 1; i < lines.length; i++) {
            const fieldCount = this.parseCSVLine(lines[i]).length
            if (fieldCount !== headerFieldCount) {
              warnings.push(`ç¬¬${i + 1}è¡Œå­—æ®µæ•°(${fieldCount})ä¸æ ‡é¢˜è¡Œ(${headerFieldCount})ä¸ä¸€è‡´`)
            }
          }
          
          return { isValid: true, errors: [], warnings }
        } catch (error) {
          return {
            isValid: false,
            errors: ['CSVéªŒè¯å¤±è´¥: ' + (error as Error).message],
            warnings: []
          }
        }
      },
      
      detectFormat: (data: string | ArrayBuffer): string | null => {
        const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
        const lines = stringData.split('\n', 5) // åªæ£€æŸ¥å‰5è¡Œ
        
        // ç®€å•æ£€æµ‹ï¼šçœ‹æ˜¯å¦åŒ…å«é€—å·åˆ†éš”çš„æ•°æ®
        let csvScore = 0
        lines.forEach(line => {
          if (line.includes(',')) csvScore++
          if (line.includes('"')) csvScore++ // CSVé€šå¸¸åŒ…å«å¼•å·
        })
        
        return csvScore >= lines.length * 0.6 ? DataFormat.CSV : null
      },
      
      getSupportedOptions: () => ({
        fields: 'array',
        excludeFields: 'array',
        separator: 'string',
        encoding: 'string'
      })
    })

    // YAML å¤„ç†å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
    this.registerProcessor(DataFormat.YAML, {
      import: async (data: string | ArrayBuffer, options?: EnhancedImportOptions) => {
        // æ³¨æ„ï¼šå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨ä¸“ä¸šçš„YAMLè§£æåº“ï¼ˆå¦‚js-yamlï¼‰
        throw new Error('YAMLå¯¼å…¥éœ€è¦é¢å¤–çš„è§£æåº“æ”¯æŒ')
      },
      
      export: async (data: any, options?: EnhancedExportOptions) => {
        // ç®€åŒ–çš„JSONåˆ°YAMLè½¬æ¢
        return this.jsonToYaml(data, 0)
      },
      
      validate: (data: string | ArrayBuffer): ValidationResult => {
        return {
          isValid: false,
          errors: ['YAMLéªŒè¯éœ€è¦é¢å¤–çš„è§£æåº“æ”¯æŒ'],
          warnings: []
        }
      },
      
      detectFormat: (data: string | ArrayBuffer): string | null => {
        const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
        // ç®€å•æ£€æµ‹YAMLæ ¼å¼æ ‡å¿—
        if (stringData.includes('---') || /^\s*\w+:\s*/.test(stringData)) {
          return DataFormat.YAML
        }
        return null
      },
      
      getSupportedOptions: () => ({
        indent: 'number',
        flowStyle: 'boolean'
      })
    })

    // TEXT å¤„ç†å™¨
    this.registerProcessor(DataFormat.TEXT, {
      import: async (data: string | ArrayBuffer, options?: EnhancedImportOptions) => {
        const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
        return {
          content: stringData,
          lines: stringData.split('\n'),
          lineCount: stringData.split('\n').length,
          charCount: stringData.length
        }
      },
      
      export: async (data: any, options?: EnhancedExportOptions) => {
        if (typeof data === 'string') {
          return data
        } else if (typeof data === 'object' && data.content) {
          return data.content
        } else {
          return JSON.stringify(data, null, 2)
        }
      },
      
      validate: (): ValidationResult => ({
        isValid: true,
        errors: [],
        warnings: []
      }),
      
      getSupportedOptions: () => ({
        encoding: 'string',
        lineEnding: 'string'
      })
    })

    console.log('PureImportExportPorter: å†…ç½®å¤„ç†å™¨æ³¨å†Œå®Œæˆ')
  }

  // ==================== å¢å¼ºçš„å·¥å…·æ–¹æ³• ====================

  /**
   * è‡ªåŠ¨æ£€æµ‹æ•°æ®æ ¼å¼
   * 
   * é€šè¿‡åˆ†ææ•°æ®å†…å®¹ï¼Œæ™ºèƒ½è¯†åˆ«å¯èƒ½çš„æ ¼å¼ç±»å‹
   */
  private async detectDataFormat(data: string | ArrayBuffer): Promise<string> {
    const cacheKey = typeof data === 'string' ? data.substring(0, 100) : 'binary'
    
    // æ£€æŸ¥ç¼“å­˜
    const cached = this.formatDetectionCache.get(cacheKey)
    if (cached) {
      return cached
    }
    
    // éå†æ‰€æœ‰å¤„ç†å™¨è¿›è¡Œæ ¼å¼æ£€æµ‹
    for (const [format, processor] of this.processors.entries()) {
      if (processor.detectFormat) {
        const detected = processor.detectFormat(data)
        if (detected) {
          this.formatDetectionCache.set(cacheKey, detected)
          return detected
        }
      }
    }
    
    // å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ï¼Œé»˜è®¤å°è¯•JSON
    throw new Error('æ— æ³•è‡ªåŠ¨æ£€æµ‹æ•°æ®æ ¼å¼ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šæ ¼å¼')
  }

  /**
   * è®¡ç®—æ•°æ®å¤§å°
   */
  private calculateDataSize(data: string | ArrayBuffer): number {
    if (typeof data === 'string') {
      return new TextEncoder().encode(data).length
    } else {
      return data.byteLength
    }
  }

  /**
   * æ›´æ–°ä»»åŠ¡è¿›åº¦
   */
  private updateProgress(jobId: string, progress: number, stage: string, message?: string): void {
    const job = this.activeJobs.get(jobId)
    if (job) {
      job.progress = progress
      if (job.onProgress) {
        job.onProgress({
          current: progress,
          total: 100,
          percentage: progress,
          stage,
          message
        })
      }
    }
  }

  /**
   * æµå¼å¤„ç†å¤§æ•°æ®æ–‡ä»¶
   */
  private async processDataInChunks(
    processor: EnhancedDataProcessor,
    data: string | ArrayBuffer,
    options: EnhancedImportOptions,
    jobId: string
  ): Promise<any> {
    const chunkSize = options.chunkSize || 1024 * 1024 // 1MB é»˜è®¤
    const stringData = typeof data === 'string' ? data : new TextDecoder().decode(data)
    
    const chunks = []
    for (let i = 0; i < stringData.length; i += chunkSize) {
      chunks.push(stringData.slice(i, i + chunkSize))
    }
    
    const results = []
    for (let i = 0; i < chunks.length; i++) {
      this.updateProgress(jobId, 50 + (i / chunks.length) * 20, 'chunk_processing', `å¤„ç†åˆ†å— ${i + 1}/${chunks.length}`)
      
      if (processor.processChunk) {
        const chunkResult = await processor.processChunk(chunks[i], options)
        results.push(chunkResult)
      }
    }
    
    // åˆå¹¶ç»“æœ
    return this.mergeChunkResults(results)
  }

  /**
   * åˆå¹¶åˆ†å—å¤„ç†ç»“æœ
   */
  private mergeChunkResults(results: any[]): any {
    // ç®€åŒ–çš„åˆå¹¶é€»è¾‘ï¼Œå®é™…åº”æ ¹æ®æ•°æ®ç±»å‹è¿›è¡Œæ™ºèƒ½åˆå¹¶
    if (results.length === 0) return null
    if (results.length === 1) return results[0]
    
    // å¦‚æœæ˜¯æ•°ç»„ï¼Œå±•å¼€åˆå¹¶
    if (Array.isArray(results[0])) {
      return results.flat()
    }
    
    // å¦‚æœæ˜¯å¯¹è±¡ï¼Œåˆå¹¶å±æ€§
    if (typeof results[0] === 'object') {
      return Object.assign({}, ...results)
    }
    
    // å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ‹¼æ¥
    if (typeof results[0] === 'string') {
      return results.join('')
    }
    
    return results
  }

  /**
   * æ›´æ–°æ ¼å¼ç»Ÿè®¡ä¿¡æ¯
   */
  private updateStats(format: string, operation: 'import' | 'export', processingTime: number, dataSize: number, success: boolean): void {
    if (!this.stats.formatStats[format]) {
      this.stats.formatStats[format] = {
        imports: 0,
        exports: 0,
        errors: 0,
        avgProcessingTime: 0
      }
    }
    
    const formatStats = this.stats.formatStats[format]
    
    if (operation === 'import') {
      formatStats.imports++
    } else {
      formatStats.exports++
    }
    
    if (!success) {
      formatStats.errors++
    }
    
    // æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
    const totalOperations = formatStats.imports + formatStats.exports
    formatStats.avgProcessingTime = 
      (formatStats.avgProcessingTime * (totalOperations - 1) + processingTime) / totalOperations
    
    // æ›´æ–°å…¨å±€æ€§èƒ½ç»Ÿè®¡
    const performanceStats = this.stats.performanceStats
    if (operation === 'import') {
      performanceStats.avgImportTime = 
        (performanceStats.avgImportTime * (this.stats.totalImports - 1) + processingTime) / this.stats.totalImports
    } else {
      performanceStats.avgExportTime = 
        (performanceStats.avgExportTime * (this.stats.totalExports - 1) + processingTime) / this.stats.totalExports
    }
  }

  /**
   * æ›´æ–°é”™è¯¯åˆ†ç±»ç»Ÿè®¡
   */
  private updateErrorCategory(category: string): void {
    this.stats.errorCategories[category] = (this.stats.errorCategories[category] || 0) + 1
  }

  /**
   * è¿‡æ»¤å¯¼å‡ºæ•°æ®
   */
  private filterExportData(data: any, options: EnhancedExportOptions): any {
    let filtered = data
    
    // å­—æ®µè¿‡æ»¤
    if (options.fields && Array.isArray(filtered)) {
      filtered = filtered.map(item => {
        const filteredItem: any = {}
        options.fields!.forEach(field => {
          if (item.hasOwnProperty(field)) {
            filteredItem[field] = item[field]
          }
        })
        return filteredItem
      })
    }
    
    // æ’é™¤å­—æ®µ
    if (options.excludeFields && Array.isArray(filtered)) {
      filtered = filtered.map(item => {
        const filteredItem = { ...item }
        options.excludeFields!.forEach(field => {
          delete filteredItem[field]
        })
        return filteredItem
      })
    }
    
    // æ•°æ®è¿‡æ»¤
    if (options.dataFilter && Array.isArray(filtered)) {
      filtered = filtered.filter(options.dataFilter)
    }
    
    return filtered
  }

  /**
   * æ·»åŠ å¯¼å‡ºå…ƒæ•°æ®
   */
  private addExportMetadata(data: any, options: EnhancedExportOptions): any {
    const exportData = { ...data }
    
    if (options.includeTimestamp) {
      exportData._metadata = {
        ...exportData._metadata,
        exportTime: Date.now(),
        exportDate: new Date().toISOString()
      }
    }
    
    if (options.includeSchema) {
      exportData._metadata = {
        ...exportData._metadata,
        schema: this.generateDataSchema(data)
      }
    }
    
    if (options.customMetadata) {
      exportData._metadata = {
        ...exportData._metadata,
        ...options.customMetadata
      }
    }
    
    return exportData
  }

  /**
   * ç”Ÿæˆæ•°æ®ç»“æ„æè¿°
   */
  private generateDataSchema(data: any): any {
    if (Array.isArray(data)) {
      if (data.length > 0) {
        return {
          type: 'array',
          itemType: typeof data[0],
          itemSchema: this.generateDataSchema(data[0])
        }
      }
      return { type: 'array' }
    }
    
    if (typeof data === 'object' && data !== null) {
      const schema: any = { type: 'object', properties: {} }
      Object.keys(data).forEach(key => {
        schema.properties[key] = this.generateDataSchema(data[key])
      })
      return schema
    }
    
    return { type: typeof data }
  }

  /**
   * æ•°æ®å‹ç¼©ï¼ˆç®€åŒ–ç‰ˆï¼‰
   */
  private async compressData(data: string, options: EnhancedExportOptions): Promise<string> {
    // ç®€åŒ–çš„å‹ç¼©ï¼šç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ
    if (options.format === DataFormat.JSON) {
      try {
        const parsed = JSON.parse(data)
        return JSON.stringify(parsed) // æ— ç¼©è¿›å‹ç¼©
      } catch {
        return data.replace(/\s+/g, ' ').trim()
      }
    }
    
    // å…¶ä»–æ ¼å¼çš„é€šç”¨å‹ç¼©
    return data.replace(/\s+/g, ' ').trim()
  }

  /**
   * ç¼–ç è½¬æ¢
   */
  private convertEncoding(data: string, encoding: string): ArrayBuffer {
    // ç®€åŒ–çš„ç¼–ç è½¬æ¢å®ç°
    if (encoding === 'utf-8') {
      return new TextEncoder().encode(data).buffer
    }
    
    // å®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨ä¸“ä¸šçš„ç¼–ç è½¬æ¢åº“
    console.warn('PureImportExportPorter: ä¸æ”¯æŒçš„ç¼–ç æ ¼å¼', encoding)
    return new TextEncoder().encode(data).buffer
  }

  // ==================== æ ¼å¼è½¬æ¢å·¥å…·æ–¹æ³• ====================

  /**
   * XML è½¬ JSON
   */
  private xmlToJson(xml: Element): any {
    const result: any = {}
    
    // å¤„ç†å±æ€§
    if (xml.attributes.length > 0) {
      result['@attributes'] = {}
      for (let i = 0; i < xml.attributes.length; i++) {
        const attr = xml.attributes[i]
        result['@attributes'][attr.name] = attr.value
      }
    }
    
    // å¤„ç†å­èŠ‚ç‚¹
    if (xml.children.length > 0) {
      for (let i = 0; i < xml.children.length; i++) {
        const child = xml.children[i] as Element
        const childData = this.xmlToJson(child)
        
        if (result[child.tagName]) {
          if (!Array.isArray(result[child.tagName])) {
            result[child.tagName] = [result[child.tagName]]
          }
          result[child.tagName].push(childData)
        } else {
          result[child.tagName] = childData
        }
      }
    } else if (xml.textContent) {
      return xml.textContent
    }
    
    return result
  }

  /**
   * JSON è½¬ XML
   */
  private jsonToXml(data: any, indent: string = '', level: number = 0): string {
    if (typeof data !== 'object' || data === null) {
      return String(data)
    }
    
    const currentIndent = indent.repeat(level)
    const nextIndent = indent.repeat(level + 1)
    let xml = ''
    
    if (Array.isArray(data)) {
      data.forEach(item => {
        xml += `${currentIndent}<item>\n`
        xml += `${nextIndent}${this.jsonToXml(item, indent, level + 1)}\n`
        xml += `${currentIndent}</item>\n`
      })
    } else {
      Object.keys(data).forEach(key => {
        const value = data[key]
        if (key === '@attributes') return // è·³è¿‡å±æ€§æ ‡è®°
        
        xml += `${currentIndent}<${key}>`
        if (typeof value === 'object' && value !== null) {
          xml += `\n${this.jsonToXml(value, indent, level + 1)}\n${currentIndent}`
        } else {
          xml += this.escapeXmlContent(String(value))
        }
        xml += `</${key}>\n`
      })
    }
    
    return xml
  }

  /**
   * JSON è½¬ YAMLï¼ˆç®€åŒ–ç‰ˆï¼‰
   */
  private jsonToYaml(data: any, level: number): string {
    const indent = '  '.repeat(level)
    
    if (typeof data !== 'object' || data === null) {
      return String(data)
    }
    
    if (Array.isArray(data)) {
      return data.map(item => `${indent}- ${this.jsonToYaml(item, level + 1)}`).join('\n')
    }
    
    return Object.keys(data).map(key => {
      const value = data[key]
      if (typeof value === 'object' && value !== null) {
        return `${indent}${key}:\n${this.jsonToYaml(value, level + 1)}`
      } else {
        return `${indent}${key}: ${value}`
      }
    }).join('\n')
  }

  /**
   * è§£æ CSV è¡Œ
   */
  private parseCSVLine(line: string): string[] {
    const result: string[] = []
    let current = ''
    let inQuotes = false
    
    for (let i = 0; i < line.length; i++) {
      const char = line[i]
      
      if (char === '"') {
        if (inQuotes && line[i + 1] === '"') {
          current += '"'
          i++ // è·³è¿‡ä¸‹ä¸€ä¸ªå¼•å·
        } else {
          inQuotes = !inQuotes
        }
      } else if (char === ',' && !inQuotes) {
        result.push(current)
        current = ''
      } else {
        current += char
      }
    }
    
    result.push(current)
    return result
  }

  /**
   * è½¬ä¹‰ CSV å­—æ®µ
   */
  private escapeCSVField(field: string): string {
    if (field.includes(',') || field.includes('"') || field.includes('\n')) {
      return `"${field.replace(/"/g, '""')}"`
    }
    return field
  }

  /**
   * è½¬ä¹‰ XML å†…å®¹
   */
  private escapeXmlContent(content: string): string {
    return content
      .replace(/&/g, '&amp;')
      .replace(/</g, '&lt;')
      .replace(/>/g, '&gt;')
      .replace(/"/g, '&quot;')
      .replace(/'/g, '&apos;')
  }

  /**
   * å‡†å¤‡å¯¼å‡ºæ•°æ® - å¢å¼ºç‰ˆ
   */
  private async prepareExportData(options: EnhancedExportOptions): Promise<any> {
    // ä»æ•°æ®æºè·å–æ•°æ®
    let panelData = {}
    
    if (this.dataSource) {
      try {
        panelData = await this.dataSource.getPanelData()
        console.log('PureImportExportPorter Enhanced: ä»æ•°æ®æºè·å–é¢æ¿æ•°æ®', panelData)
      } catch (error) {
        console.error('PureImportExportPorter Enhanced: ä»æ•°æ®æºè·å–æ•°æ®å¤±è´¥', error)
        // å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨ç©ºæ•°æ®
        panelData = { nodes: [], meta: {} }
      }
    } else {
      console.warn('PureImportExportPorter Enhanced: æœªè®¾ç½®æ•°æ®æºï¼Œä½¿ç”¨ç©ºæ•°æ®')
      panelData = { nodes: [], meta: {} }
    }
    
    const exportData = {
      panel: panelData,
      metadata: {
        exportTime: Date.now(),
        version: '2.0.0',
        format: 'panelv2-clean-enhanced',
        ...options.customMetadata
      }
    }
    
    return exportData
  }

  /**
   * é”€æ¯é—¨æˆ· - å¢å¼ºç‰ˆ
   * 
   * æ¸…ç†æ‰€æœ‰èµ„æºï¼Œç¡®ä¿æ²¡æœ‰å†…å­˜æ³„æ¼
   */
  destroy(): void {
    // å–æ¶ˆæ‰€æœ‰æ´»è·ƒä»»åŠ¡
    for (const jobId of this.activeJobs.keys()) {
      this.cancelJob(jobId)
    }
    
    // æ¸…ç†å¤„ç†å™¨
    this.processors.clear()
    
    // æ¸…ç†ç¼“å­˜
    this.formatDetectionCache.clear()
    
    // æ¸…ç†æ•°æ®æºå¼•ç”¨
    this.dataSource = null
    
    console.log('PureImportExportPorter Enhanced: å¢å¼ºç‰ˆå¯¼å…¥å¯¼å‡ºé—¨æˆ·å·²é”€æ¯')
  }
}

/**
 * åˆ›å»ºå¢å¼ºç‰ˆçº¯å‡€å¯¼å…¥å¯¼å‡ºé—¨æˆ·å®ä¾‹
 * 
 * å·¥å‚å‡½æ•°ï¼Œæä¾›æ ‡å‡†åŒ–çš„å®ä¾‹åˆ›å»ºæ–¹å¼
 */
export const createPureImportExportPorter = (): PureImportExportPorter => {
  console.log('åˆ›å»ºPureImportExportPorter Enhancedå®ä¾‹')
  return new PureImportExportPorter()
}

/**
 * åˆ›å»ºå¸¦é…ç½®çš„å¢å¼ºç‰ˆå¯¼å…¥å¯¼å‡ºé—¨æˆ·
 * 
 * æ”¯æŒé¢„é…ç½®å¤„ç†å™¨å’Œæ•°æ®æº
 */
export const createConfiguredImportExportPorter = (config?: {
  dataSource?: DataSource
  additionalProcessors?: Map<string, EnhancedDataProcessor>
  enabledFormats?: DataFormat[]
}): PureImportExportPorter => {
  const porter = new PureImportExportPorter()
  
  // è®¾ç½®æ•°æ®æº
  if (config?.dataSource) {
    porter.setDataSource(config.dataSource)
  }
  
  // æ³¨å†Œé¢å¤–çš„å¤„ç†å™¨
  if (config?.additionalProcessors) {
    for (const [format, processor] of config.additionalProcessors.entries()) {
      porter.registerProcessor(format, processor)
    }
  }
  
  // å¦‚æœæŒ‡å®šäº†å¯ç”¨çš„æ ¼å¼ï¼Œå¯ä»¥ç§»é™¤ä¸éœ€è¦çš„å¤„ç†å™¨
  if (config?.enabledFormats) {
    const supportedFormats = porter.getSupportedFormats()
    supportedFormats.formats.forEach(format => {
      if (!config.enabledFormats!.includes(format as DataFormat)) {
        // æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ·»åŠ ç§»é™¤å¤„ç†å™¨çš„æ–¹æ³•
        console.log(`å·²ç¦ç”¨æ ¼å¼: ${format}`)
      }
    })
  }
  
  console.log('åˆ›å»ºå·²é…ç½®çš„PureImportExportPorter Enhancedå®ä¾‹', config)
  return porter
}

/**
 * å…¨å±€å¯¼å…¥å¯¼å‡ºé—¨æˆ·å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
 */
let _globalImportExportPorter: PureImportExportPorter | null = null

export const globalImportExportPorter = new Proxy({} as PureImportExportPorter, {
  get(target, prop) {
    if (!_globalImportExportPorter) {
      console.log('globalImportExportPorter Proxy: å»¶è¿Ÿåˆå§‹åŒ–å¢å¼ºç‰ˆé—¨æˆ·')
      _globalImportExportPorter = createPureImportExportPorter()
    }
    return _globalImportExportPorter[prop as keyof PureImportExportPorter]
  }
})

/**
 * å¯¼å‡ºæ‰€æœ‰ç›¸å…³ç±»å‹å’Œæšä¸¾ï¼Œæ–¹ä¾¿å¤–éƒ¨ä½¿ç”¨
 */
export type {
  EnhancedDataProcessor,
  EnhancedImportOptions,
  EnhancedExportOptions,
  ProgressCallback,
  TransformResult
}